{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "efn = EfficientNet.from_name('efficientnet-b6', include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 56, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "  )\n",
       "  (_bn0): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        56, 56, kernel_size=(3, 3), stride=[1, 1], groups=56, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        56, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        14, 56, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        56, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        192, 192, kernel_size=(3, 3), stride=[2, 2], groups=192, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        192, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 72, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(72, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(432, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        432, 432, kernel_size=(5, 5), stride=(1, 1), groups=432, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(432, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        432, 18, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        18, 432, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        432, 72, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(72, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(432, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        432, 432, kernel_size=(5, 5), stride=(1, 1), groups=432, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(432, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        432, 18, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        18, 432, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        432, 72, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(72, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(432, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        432, 432, kernel_size=(5, 5), stride=(1, 1), groups=432, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(432, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        432, 18, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        18, 432, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        432, 72, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(72, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(432, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        432, 432, kernel_size=(5, 5), stride=(1, 1), groups=432, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(432, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        432, 18, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        18, 432, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        432, 72, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(72, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(432, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        432, 432, kernel_size=(5, 5), stride=(1, 1), groups=432, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(432, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        432, 18, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        18, 432, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        432, 72, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(72, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(432, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        432, 432, kernel_size=(3, 3), stride=[2, 2], groups=432, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(432, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        432, 18, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        18, 432, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        432, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(864, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        864, 864, kernel_size=(3, 3), stride=(1, 1), groups=864, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(864, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        864, 36, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        36, 864, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        864, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(864, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        864, 864, kernel_size=(3, 3), stride=(1, 1), groups=864, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(864, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        864, 36, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        36, 864, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        864, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(864, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        864, 864, kernel_size=(3, 3), stride=(1, 1), groups=864, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(864, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        864, 36, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        36, 864, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        864, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(864, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        864, 864, kernel_size=(3, 3), stride=(1, 1), groups=864, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(864, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        864, 36, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        36, 864, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        864, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(864, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        864, 864, kernel_size=(3, 3), stride=(1, 1), groups=864, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(864, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        864, 36, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        36, 864, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        864, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(864, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        864, 864, kernel_size=(3, 3), stride=(1, 1), groups=864, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(864, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        864, 36, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        36, 864, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        864, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(864, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        864, 864, kernel_size=(3, 3), stride=(1, 1), groups=864, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(864, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        864, 36, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        36, 864, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        864, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(864, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        864, 864, kernel_size=(5, 5), stride=[1, 1], groups=864, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(864, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        864, 36, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        36, 864, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        864, 200, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1200, 1200, kernel_size=(5, 5), stride=(1, 1), groups=1200, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1200, 50, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        50, 1200, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1200, 200, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1200, 1200, kernel_size=(5, 5), stride=(1, 1), groups=1200, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1200, 50, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        50, 1200, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1200, 200, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (26): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1200, 1200, kernel_size=(5, 5), stride=(1, 1), groups=1200, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1200, 50, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        50, 1200, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1200, 200, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (27): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1200, 1200, kernel_size=(5, 5), stride=(1, 1), groups=1200, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1200, 50, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        50, 1200, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1200, 200, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (28): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1200, 1200, kernel_size=(5, 5), stride=(1, 1), groups=1200, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1200, 50, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        50, 1200, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1200, 200, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (29): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1200, 1200, kernel_size=(5, 5), stride=(1, 1), groups=1200, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1200, 50, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        50, 1200, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1200, 200, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (30): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1200, 1200, kernel_size=(5, 5), stride=(1, 1), groups=1200, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1200, 50, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        50, 1200, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1200, 200, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (31): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1200, 1200, kernel_size=(5, 5), stride=[2, 2], groups=1200, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1200, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1200, 50, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        50, 1200, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1200, 344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (32): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2064, 2064, kernel_size=(5, 5), stride=(1, 1), groups=2064, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2064, 86, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        86, 2064, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (33): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2064, 2064, kernel_size=(5, 5), stride=(1, 1), groups=2064, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2064, 86, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        86, 2064, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (34): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2064, 2064, kernel_size=(5, 5), stride=(1, 1), groups=2064, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2064, 86, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        86, 2064, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (35): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2064, 2064, kernel_size=(5, 5), stride=(1, 1), groups=2064, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2064, 86, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        86, 2064, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (36): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2064, 2064, kernel_size=(5, 5), stride=(1, 1), groups=2064, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2064, 86, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        86, 2064, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (37): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2064, 2064, kernel_size=(5, 5), stride=(1, 1), groups=2064, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2064, 86, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        86, 2064, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (38): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2064, 2064, kernel_size=(5, 5), stride=(1, 1), groups=2064, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2064, 86, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        86, 2064, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (39): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2064, 2064, kernel_size=(5, 5), stride=(1, 1), groups=2064, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2064, 86, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        86, 2064, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (40): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2064, 2064, kernel_size=(5, 5), stride=(1, 1), groups=2064, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2064, 86, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        86, 2064, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (41): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2064, 2064, kernel_size=(5, 5), stride=(1, 1), groups=2064, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2064, 86, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        86, 2064, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (42): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2064, 2064, kernel_size=(3, 3), stride=[1, 1], groups=2064, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(2064, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2064, 86, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        86, 2064, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2064, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (43): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        576, 3456, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(3456, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        3456, 3456, kernel_size=(3, 3), stride=(1, 1), groups=3456, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(3456, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        3456, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        144, 3456, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        3456, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (44): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        576, 3456, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(3456, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        3456, 3456, kernel_size=(3, 3), stride=(1, 1), groups=3456, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(3456, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        3456, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        144, 3456, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        3456, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    576, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (_fc): Linear(in_features=2304, out_features=1000, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['SENet', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152',\n",
    "           'se_resnext50_32x4d', 'se_resnext101_32x4d']\n",
    "\n",
    "pretrained_settings = {\n",
    "    'senet154': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/senet154-c7b49a05.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnet50': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet50-ce0d4300.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnet101': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet101-7e38fcc6.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnet152': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet152-d17c99b7.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnext50_32x4d': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnext101_32x4d': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, absolute_import\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "from torch.utils import model_zoo\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(\n",
    "            channels, channels // reduction, kernel_size=1, padding=0\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(\n",
    "            channels // reduction, channels, kernel_size=1, padding=0\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for bottlenecks that implements `forward()` method.\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = self.se_module(out) + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class SEBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    Bottleneck for SENet154.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(\n",
    "        self, inplanes, planes, groups, reduction, stride=1, downsample=None\n",
    "    ):\n",
    "        super(SEBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes * 2)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            planes * 2,\n",
    "            planes * 4,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            groups=groups,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(planes * 4)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            planes * 4, planes * 4, kernel_size=1, bias=False\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        \n",
    "\n",
    "class SEResNetBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n",
    "    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n",
    "    (the latter is used in the torchvision implementation of ResNet).\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(\n",
    "        self, inplanes, planes, groups, reduction, stride=1, downsample=None\n",
    "    ):\n",
    "        super(SEResNetBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            inplanes, planes, kernel_size=1, bias=False, stride=stride\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            planes,\n",
    "            planes,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            groups=groups,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNeXtBottleneck(Bottleneck):\n",
    "    \"\"\"ResNeXt bottleneck type C with a Squeeze-and-Excitation module\"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes,\n",
    "        planes,\n",
    "        groups,\n",
    "        reduction,\n",
    "        stride=1,\n",
    "        downsample=None,\n",
    "        base_width=4\n",
    "    ):\n",
    "        super(SEResNeXtBottleneck, self).__init__()\n",
    "        width = int(math.floor(planes * (base_width/64.)) * groups)\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            inplanes, width, kernel_size=1, bias=False, stride=1\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            width,\n",
    "            width,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            groups=groups,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(width)\n",
    "        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SENet(nn.Module):\n",
    "    \"\"\"Squeeze-and-excitation network.\n",
    "    \n",
    "    Reference:\n",
    "        Hu et al. Squeeze-and-Excitation Networks. CVPR 2018.\n",
    "    Public keys:\n",
    "        - ``senet154``: SENet154.\n",
    "        - ``se_resnet50``: ResNet50 + SE.\n",
    "        - ``se_resnet101``: ResNet101 + SE.\n",
    "        - ``se_resnet152``: ResNet152 + SE.\n",
    "        - ``se_resnext50_32x4d``: ResNeXt50 (groups=32, width=4) + SE.\n",
    "        - ``se_resnext101_32x4d``: ResNeXt101 (groups=32, width=4) + SE.\n",
    "        - ``se_resnet50_fc512``: (ResNet50 + SE) + FC.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        block,\n",
    "        layers,\n",
    "        groups,\n",
    "        reduction,\n",
    "        dropout_p=0.2,\n",
    "        inplanes=128,\n",
    "        input_3x3=True,\n",
    "        downsample_kernel_size=3,\n",
    "        downsample_padding=1,\n",
    "        last_stride=2,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        block (nn.Module): Bottleneck class.\n",
    "            - For SENet154: SEBottleneck\n",
    "            - For SE-ResNet models: SEResNetBottleneck\n",
    "            - For SE-ResNeXt models:  SEResNeXtBottleneck\n",
    "        layers (list of ints): Number of residual blocks for 4 layers of the\n",
    "            network (layer1...layer4).\n",
    "        groups (int): Number of groups for the 3x3 convolution in each\n",
    "            bottleneck block.\n",
    "            - For SENet154: 64\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models:  32\n",
    "        reduction (int): Reduction ratio for Squeeze-and-Excitation modules.\n",
    "            - For all models: 16\n",
    "        dropout_p (float or None): Drop probability for the Dropout layer.\n",
    "            If `None` the Dropout layer is not used.\n",
    "            - For SENet154: 0.2\n",
    "            - For SE-ResNet models: None\n",
    "            - For SE-ResNeXt models: None\n",
    "        inplanes (int):  Number of input channels for layer1.\n",
    "            - For SENet154: 128\n",
    "            - For SE-ResNet models: 64\n",
    "            - For SE-ResNeXt models: 64\n",
    "        input_3x3 (bool): If `True`, use three 3x3 convolutions instead of\n",
    "            a single 7x7 convolution in layer0.\n",
    "            - For SENet154: True\n",
    "            - For SE-ResNet models: False\n",
    "            - For SE-ResNeXt models: False\n",
    "        downsample_kernel_size (int): Kernel size for downsampling convolutions\n",
    "            in layer2, layer3 and layer4.\n",
    "            - For SENet154: 3\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models: 1\n",
    "        downsample_padding (int): Padding for downsampling convolutions in\n",
    "            layer2, layer3 and layer4.\n",
    "            - For SENet154: 1\n",
    "            - For SE-ResNet models: 0\n",
    "            - For SE-ResNeXt models: 0\n",
    "        num_classes (int): Number of outputs in `classifier` layer.\n",
    "        \"\"\"\n",
    "        super(SENet, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "\n",
    "        if input_3x3:\n",
    "            layer0_modules = [\n",
    "                (\n",
    "                    'conv1',\n",
    "                    nn.Conv2d(3, 64, 3, stride=2, padding=1, bias=False)\n",
    "                ),\n",
    "                ('bn1', nn.BatchNorm2d(64)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "                (\n",
    "                    'conv2',\n",
    "                    nn.Conv2d(64, 64, 3, stride=1, padding=1, bias=False)\n",
    "                ),\n",
    "                ('bn2', nn.BatchNorm2d(64)),\n",
    "                ('relu2', nn.ReLU(inplace=True)),\n",
    "                (\n",
    "                    'conv3',\n",
    "                    nn.Conv2d(\n",
    "                        64, inplanes, 3, stride=1, padding=1, bias=False\n",
    "                    )\n",
    "                ),\n",
    "                ('bn3', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu3', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        else:\n",
    "            layer0_modules = [\n",
    "                (\n",
    "                    'conv1',\n",
    "                    nn.Conv2d(\n",
    "                        3,\n",
    "                        inplanes,\n",
    "                        kernel_size=7,\n",
    "                        stride=2,\n",
    "                        padding=3,\n",
    "                        bias=False\n",
    "                    )\n",
    "                ),\n",
    "                ('bn1', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        # To preserve compatibility with Caffe weights `ceil_mode=True`\n",
    "        # is used instead of `padding=1`.\n",
    "        layer0_modules.append(\n",
    "            ('pool', nn.MaxPool2d(3, stride=2, ceil_mode=True))\n",
    "        )\n",
    "        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n",
    "        self.layer1 = self._make_layer(\n",
    "            block,\n",
    "            planes=64,\n",
    "            blocks=layers[0],\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=1,\n",
    "            downsample_padding=0\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block,\n",
    "            planes=128,\n",
    "            blocks=layers[1],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block,\n",
    "            planes=256,\n",
    "            blocks=layers[2],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block,\n",
    "            planes=512,\n",
    "            blocks=layers[3],\n",
    "            stride=last_stride,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "\n",
    "        self.global_avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "\n",
    "    def _make_layer(\n",
    "        self,\n",
    "        block,\n",
    "        planes,\n",
    "        blocks,\n",
    "        groups,\n",
    "        reduction,\n",
    "        stride=1,\n",
    "        downsample_kernel_size=1,\n",
    "        downsample_padding=0\n",
    "    ):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    self.inplanes,\n",
    "                    planes * block.expansion,\n",
    "                    kernel_size=downsample_kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=downsample_padding,\n",
    "                    bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.inplanes, planes, groups, reduction, stride, downsample\n",
    "            )\n",
    "        )\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups, reduction))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def featuremaps(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.featuremaps(x)\n",
    "        v = self.global_avgpool(f)\n",
    "        v = v.view(v.size(0), -1)\n",
    "        \n",
    "        return v\n",
    "\n",
    "\n",
    "\n",
    "def init_pretrained_weights(model, model_url):\n",
    "    \"\"\"Initializes model with pretrained weights.\n",
    "    \n",
    "    Layers that don't match with pretrained layers in name or size are kept unchanged.\n",
    "    \"\"\"\n",
    "    pretrain_dict = model_zoo.load_url(model_url)\n",
    "    model_dict = model.state_dict()\n",
    "    pretrain_dict = {\n",
    "        k: v\n",
    "        for k, v in pretrain_dict.items()\n",
    "        if k in model_dict and model_dict[k].size() == v.size()\n",
    "    }\n",
    "    model_dict.update(pretrain_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def se_resnext50_32x4d( pretrained=True, **kwargs):\n",
    "    model = SENet(\n",
    "        block=SEResNeXtBottleneck,\n",
    "        layers=[3, 4, 6, 3],\n",
    "        groups=32,\n",
    "        reduction=16,\n",
    "        dropout_p=None,\n",
    "        inplanes=64,\n",
    "        input_3x3=False,\n",
    "        downsample_kernel_size=1,\n",
    "        downsample_padding=0,\n",
    "        last_stride=2,\n",
    "        **kwargs\n",
    "    )\n",
    "    if pretrained:\n",
    "        model_url = pretrained_settings['se_resnext50_32x4d']['imagenet']['url'\n",
    "                                                                          ]\n",
    "        init_pretrained_weights(model, model_url)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnext101_32x4d( pretrained=True, **kwargs):\n",
    "    model = SENet(\n",
    "        block=SEResNeXtBottleneck,\n",
    "        layers=[3, 4, 23, 3],\n",
    "        groups=32,\n",
    "        reduction=16,\n",
    "        dropout_p=None,\n",
    "        inplanes=64,\n",
    "        input_3x3=False,\n",
    "        downsample_kernel_size=1,\n",
    "        downsample_padding=0,\n",
    "        last_stride=2,\n",
    "        **kwargs\n",
    "    )\n",
    "    if pretrained:\n",
    "        model_url = pretrained_settings['se_resnext101_32x4d']['imagenet'][\n",
    "            'url']\n",
    "        init_pretrained_weights(model, model_url)\n",
    "    return model\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENet(\n",
      "  (layer0): Sequential(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (0): SEResNeXtBottleneck(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): SEResNeXtBottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): SEResNeXtBottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): SEResNeXtBottleneck(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): SEResNeXtBottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): SEResNeXtBottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (3): SEResNeXtBottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): SEResNeXtBottleneck(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): SEResNeXtBottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): SEResNeXtBottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (3): SEResNeXtBottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (4): SEResNeXtBottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (5): SEResNeXtBottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): SEResNeXtBottleneck(\n",
      "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): SEResNeXtBottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): SEResNeXtBottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (se_module): SEModule(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(se_resnext50_32x4d())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = se_resnext50_32x4d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2048])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model(torch.zeros((8, 3, 512, 512))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEResNext50(nn.Module):\n",
    "    def __init__(self, middle_layer = 1024, output_layer = 5):\n",
    "        super(SEResNext50, self).__init__()\n",
    "        self.senet = se_resnext50_32x4d()\n",
    "        self.elu = nn.ELU()\n",
    "        self.fc1 = nn.Linear(2048, middle_layer)\n",
    "        self.fc2 = nn.Linear(middle_layer, output_layer)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.senet(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.elu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "model = SEResNext50(512, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0213, -0.0576,  0.0745,  0.0843,  0.1075],\n",
       "        [-0.0213, -0.0576,  0.0745,  0.0843,  0.1075],\n",
       "        [-0.0213, -0.0576,  0.0745,  0.0843,  0.1075],\n",
       "        [-0.0213, -0.0576,  0.0745,  0.0843,  0.1075],\n",
       "        [-0.0213, -0.0576,  0.0745,  0.0843,  0.1075],\n",
       "        [-0.0213, -0.0576,  0.0745,  0.0843,  0.1075],\n",
       "        [-0.0213, -0.0576,  0.0745,  0.0843,  0.1075],\n",
       "        [-0.0213, -0.0576,  0.0745,  0.0843,  0.1075]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.zeros((8, 3, 512, 512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfnB6(nn.Module):\n",
    "    \n",
    "    def __init__(self, middle_layer = 1024, output_layer = 5):\n",
    "        super(EfnB6, self).__init__()\n",
    "        self.efn = EfficientNet.from_name('efficientnet-b6', include_top = False)\n",
    "        self.elu = nn.ELU()\n",
    "        self.fc1 = nn.Linear(2304, middle_layer)\n",
    "        self.fc2 = nn.Linear(middle_layer, output_layer)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.efn(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.elu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# model = EfnB6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from catalyst.contrib import registry\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "def log_t(u, t):\n",
    "    \"\"\"Compute log_t for `u`.\"\"\"\n",
    "\n",
    "    if t == 1.0:\n",
    "        return torch.log(u)\n",
    "    else:\n",
    "        return (u ** (1.0 - t) - 1.0) / (1.0 - t)\n",
    "\n",
    "\n",
    "def exp_t(u, t):\n",
    "    \"\"\"Compute exp_t for `u`.\"\"\"\n",
    "\n",
    "    if t == 1.0:\n",
    "        return torch.exp(u)\n",
    "    else:\n",
    "        return torch.relu(1.0 + (1.0 - t) * u) ** (1.0 / (1.0 - t))\n",
    "\n",
    "\n",
    "def compute_normalization_fixed_point(activations, t, num_iters=5):\n",
    "    \"\"\"Returns the normalization value for each example (t > 1.0).\n",
    "    Args:\n",
    "    activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "    t: Temperature 2 (> 1.0 for tail heaviness).\n",
    "    num_iters: Number of iterations to run the method.\n",
    "    Return: A tensor of same rank as activation with the last dimension being 1.\n",
    "    \"\"\"\n",
    "\n",
    "    mu = torch.max(activations, dim=-1).values.view(-1, 1)\n",
    "    normalized_activations_step_0 = activations - mu\n",
    "\n",
    "    normalized_activations = normalized_activations_step_0\n",
    "    i = 0\n",
    "    while i < num_iters:\n",
    "        i += 1\n",
    "        logt_partition = torch.sum(exp_t(normalized_activations, t), dim=-1).view(-1, 1)\n",
    "        normalized_activations = normalized_activations_step_0 * (logt_partition ** (1.0 - t))\n",
    "\n",
    "    logt_partition = torch.sum(exp_t(normalized_activations, t), dim=-1).view(-1, 1)\n",
    "\n",
    "    return -log_t(1.0 / logt_partition, t) + mu\n",
    "\n",
    "\n",
    "def compute_normalization(activations, t, num_iters=5):\n",
    "    \"\"\"Returns the normalization value for each example.\n",
    "    Args:\n",
    "    activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "    t: Temperature 2 (< 1.0 for finite support, > 1.0 for tail heaviness).\n",
    "    num_iters: Number of iterations to run the method.\n",
    "    Return: A tensor of same rank as activation with the last dimension being 1.\n",
    "    \"\"\"\n",
    "\n",
    "    if t < 1.0:\n",
    "        return None # not implemented as these values do not occur in the authors experiments...\n",
    "    else:\n",
    "        return compute_normalization_fixed_point(activations, t, num_iters)\n",
    "\n",
    "\n",
    "def tempered_softmax(activations, t, num_iters=5):\n",
    "    \"\"\"Tempered softmax function.\n",
    "    Args:\n",
    "    activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "    t: Temperature tensor > 0.0.\n",
    "    num_iters: Number of iterations to run the method.\n",
    "    Returns:\n",
    "    A probabilities tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    if t == 1.0:\n",
    "        normalization_constants = torch.log(torch.sum(torch.exp(activations), dim=-1))\n",
    "    else:\n",
    "        normalization_constants = compute_normalization(activations, t, num_iters)\n",
    "\n",
    "    return exp_t(activations - normalization_constants, t)\n",
    "\n",
    "\n",
    "def bi_tempered_logistic_loss(activations, labels, t1, t2, label_smoothing=0.0, num_iters=5, num_classes = 5):\n",
    "\n",
    "    \"\"\"Bi-Tempered Logistic Loss with custom gradient.\n",
    "    Args:\n",
    "    activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "    labels: A tensor with shape and dtype as activations.\n",
    "    t1: Temperature 1 (< 1.0 for boundedness).\n",
    "    t2: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n",
    "    label_smoothing: Label smoothing parameter between [0, 1).\n",
    "    num_iters: Number of iterations to run the method.\n",
    "    Returns:\n",
    "    A loss tensor.\n",
    "    \"\"\"\n",
    "    target = F.one_hot(labels, num_classes).float()\n",
    "\n",
    "    if label_smoothing > 0.0:\n",
    "        target = (1 - num_classes / (num_classes - 1) * label_smoothing) * target + label_smoothing / (num_classes - 1)\n",
    "\n",
    "    probabilities = tempered_softmax(activations, t2, num_iters)\n",
    "\n",
    "    temp1 = (log_t(target + 1e-10, t1) - log_t(probabilities, t1)) * target\n",
    "    temp2 = (1 / (2 - t1)) * (torch.pow(target, 2 - t1) - torch.pow(probabilities, 2 - t1))\n",
    "    loss_values = temp1 - temp2\n",
    "\n",
    "    return torch.sum(torch.sum(loss_values, dim=-1))\n",
    "   \n",
    "    \n",
    "@registry.Criterion\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, smooth_factor=0.05):\n",
    "        super().__init__()\n",
    "        self.smooth_factor = smooth_factor\n",
    "\n",
    "    def _smooth_labels(self, num_classes, target):\n",
    "        # When label smoothing is turned on,\n",
    "        # KL-divergence between q_{smoothed ground truth prob.}(w)\n",
    "        # and p_{prob. computed by model}(w) is minimized.\n",
    "        # If label smoothing value is set to zero, the loss\n",
    "        # is equivalent to NLLLoss or CrossEntropyLoss.\n",
    "        # All non-true labels are uniformly set to low-confidence.\n",
    "\n",
    "        target_one_hot = F.one_hot(target, num_classes).float()\n",
    "        target_one_hot[target_one_hot == 1] = 1 - self.smooth_factor\n",
    "        target_one_hot[target_one_hot == 0] = self.smooth_factor\n",
    "        return target_one_hot\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logp = F.log_softmax(input, dim=1)\n",
    "        target_one_hot = self._smooth_labels(input.size(1), target)\n",
    "        return F.kl_div(logp, target_one_hot, reduction='sum')\n",
    "\n",
    "@registry.Criterion\n",
    "class TemperedLogLoss(nn.Module):\n",
    "    def __init__(self, label_smoothing=0.05, t1 = 0.7, t2 = 2, num_iters = 5):\n",
    "        super().__init__()\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.t1 = t1\n",
    "        self.t2 = t2\n",
    "        self.num_iters = num_iters\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return bi_tempered_logistic_loss(input, target, self.t1, self.t2, self.label_smoothing, self.num_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations.pytorch import ToTensor\n",
    "\n",
    "def get_super_light_augmentations(image_size):\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "    ])\n",
    "\n",
    "def get_light_augmentations(image_size):\n",
    "    min_size = min(image_size[0], image_size[1])\n",
    "    return A.Compose([\n",
    "        A.RandomSizedCrop(min_max_height=(int(min_size * 0.85), min_size),\n",
    "                          height=image_size[0],\n",
    "                          width=image_size[1], p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "    ])\n",
    "\n",
    "def get_medium_augmentations(image_size):\n",
    "    min_size = min(image_size[0], image_size[1])\n",
    "\n",
    "    return A.Compose([\n",
    "        A.OneOf([A.RandomSizedCrop(min_max_height=(int(min_size* 0.85), min_size),\n",
    "                          height=image_size[0],\n",
    "                          width=image_size[1]),\n",
    "                A.Resize(image_size[0], image_size[1]),\n",
    "                A.CenterCrop(image_size[0], image_size[1])\n",
    "                ], p = 1.0),\n",
    "\n",
    "        A.OneOf([\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.15,\n",
    "                                       contrast_limit=0.5),\n",
    "            A.RandomGamma(gamma_limit=(50, 150)),\n",
    "            A.NoOp()\n",
    "        ], p = 1.0),\n",
    "        \n",
    "        A.OneOf([A.CLAHE(p=0.5, clip_limit=(10, 10), tile_grid_size=(3, 3)),\n",
    "                A.FancyPCA(alpha=0.4),\n",
    "                A.NoOp(),\n",
    "                ], p = 1.0),\n",
    "        \n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Flip(p = 0.5)\n",
    "    ])\n",
    "\n",
    "def get_hard_augmentations(image_size):\n",
    "    return None\n",
    "\n",
    "# def get_medium_augmentations(image_size):\n",
    "#     return A.Compose([\n",
    "#         A.OneOf([\n",
    "#             A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1,\n",
    "#                                rotate_limit=15,\n",
    "#                                border_mode=cv2.BORDER_CONSTANT, value=0),\n",
    "#             A.OpticalDistortion(distort_limit=0.11, shift_limit=0.15,\n",
    "#                                 border_mode=cv2.BORDER_CONSTANT,\n",
    "#                                 value=0),\n",
    "#             A.NoOp()\n",
    "#         ]),\n",
    "#         A.RandomSizedCrop(min_max_height=(int(image_size[0] * 0.75), image_size[0]),\n",
    "#                           height=image_size[0],\n",
    "#                           width=image_size[1], p=0.3),\n",
    "#         A.OneOf([\n",
    "#             A.RandomBrightnessContrast(brightness_limit=0.5,\n",
    "#                                        contrast_limit=0.4),\n",
    "#             A.RandomGamma(gamma_limit=(50, 150)),\n",
    "#             A.NoOp()\n",
    "#         ]),\n",
    "#         A.OneOf([\n",
    "#             A.RGBShift(r_shift_limit=20, b_shift_limit=15, g_shift_limit=15),\n",
    "#             A.HueSaturationValue(hue_shift_limit=5,\n",
    "#                                  sat_shift_limit=5),\n",
    "#             A.NoOp()\n",
    "#         ]),\n",
    "#         A.HorizontalFlip(p=0.5),\n",
    "#         A.VerticalFlip(p=0.5)\n",
    "#     ])\n",
    "\n",
    "def post_transforms():\n",
    "    # we use ImageNet image normalization\n",
    "    # and convert it to torch.Tensor\n",
    "#     return [ToTensor()]\n",
    "    return A.Compose([A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                       std=(0.229, 0.224, 0.225)), ToTensor()])\n",
    "\n",
    "# def compose(transforms_to_compose):\n",
    "#     # combine all augmentations into one single pipeline\n",
    "#     result = A.Compose([\n",
    "#       item for sublist in transforms_to_compose for item in sublist\n",
    "#     ])\n",
    "#     return result\n",
    "\n",
    "\n",
    "def get_test_transform(image_size):\n",
    "    return A.Compose([A.Resize(image_size[0], image_size[1], p = 1.0), A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                       std=(0.229, 0.224, 0.225), p = 1.0), ToTensor()])\n",
    "\n",
    "def get_train_transform(augmentation, image_size):\n",
    "    LEVELS = {\n",
    "        'super_light': get_super_light_augmentations,\n",
    "        'light': get_light_augmentations,\n",
    "        'medium': get_medium_augmentations,\n",
    "        'hard': get_hard_augmentations,\n",
    "#         'hard2': get_hard_augmentations_v2\n",
    "    }\n",
    "\n",
    "    aug = LEVELS[augmentation](image_size)\n",
    "\n",
    "    return A.Compose([aug, post_transforms()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from typing import Tuple, List\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from pytorch_toolbelt.utils import fs\n",
    "# from pytorch_toolbelt.utils.fs import id_from_fname\n",
    "# from pytorch_toolbelt.utils.torch_utils import tensor_from_rgb_image\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.utils import compute_sample_weight\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "UNLABELED_CLASS = -100\n",
    "\n",
    "\n",
    "\n",
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, images, targets, img_size, \n",
    "                 transform: A.Compose,\n",
    "                 target_as_array=False,\n",
    "                 dtype=int):\n",
    "        if targets is not None:\n",
    "            targets = np.array(targets)\n",
    "            unique_targets = set(targets)\n",
    "            if len(unique_targets.difference({0, 1, 2, 3, 4, UNLABELED_CLASS})):\n",
    "                raise ValueError('Unexpected targets in Y ' + str(unique_targets))\n",
    "\n",
    "        self.images = np.array(images)\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "        self.target_as_array = target_as_array\n",
    "        self.dtype = dtype\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image = cv2.imread(self.images[item])  # Read with OpenCV instead PIL. It's faster\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(self.images[item])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        height, width = image.shape[:2]\n",
    "        label = UNLABELED_CLASS\n",
    "\n",
    "        if self.targets is not None:\n",
    "            label = self.targets[item]\n",
    "\n",
    "        #Плохо тут это делать но пока так\n",
    "        data = self.transform(image=image, label=label)\n",
    "        label = data['label']\n",
    "\n",
    "        data = {'image': data['image']}\n",
    "\n",
    "        label = self.dtype(label)\n",
    "        if self.target_as_array:\n",
    "            data['targets'] = np.array([label])\n",
    "        else:\n",
    "            data['targets'] = label\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def split_train_valid(x, y, fold=None, folds=4, random_state=42):\n",
    "    \"\"\"\n",
    "    Common train/test split function\n",
    "    :param x:\n",
    "    :param y:\n",
    "    :param fold:\n",
    "    :param folds:\n",
    "    :param random_state:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    train_x, train_y = [], []\n",
    "    valid_x, valid_y = [], []\n",
    "\n",
    "    if fold is not None:\n",
    "        assert 0 <= fold < folds\n",
    "        skf = StratifiedKFold(n_splits=folds, random_state=random_state, shuffle=True)\n",
    "\n",
    "        for fold_index, (train_index, test_index) in enumerate(skf.split(x, y)):\n",
    "            if fold_index == fold:\n",
    "                train_x = x[train_index]\n",
    "                train_y = y[train_index]\n",
    "                valid_x = x[test_index]\n",
    "                valid_y = y[test_index]\n",
    "                break\n",
    "    else:\n",
    "        train_x, valid_x, train_y, valid_y = train_test_split(x, y,\n",
    "                                                              random_state=random_state,\n",
    "                                                              test_size=1.0 / folds,\n",
    "                                                              shuffle=True,\n",
    "                                                              stratify=y)\n",
    "\n",
    "    assert len(train_x) and len(train_y) and len(valid_x) and len(valid_y)\n",
    "    assert len(train_x) == len(train_y)\n",
    "    assert len(valid_x) == len(valid_y)\n",
    "    return train_x, valid_x, train_y, valid_y\n",
    "\n",
    "\n",
    "def get_current_train(data_dir):\n",
    "    df = pd.read_csv(os.path.join(data_dir, 'train_images.csv'))\n",
    "    x = np.array(df['image_id'].apply(lambda x: os.path.join(data_dir, 'train_images', f'{x}')))\n",
    "    y = np.array(df['label'], dtype=int)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def get_extra_train(data_dir):\n",
    "    df = pd.read_csv(os.path.join(data_dir, 'extra_images.csv'))\n",
    "    x = np.array(df['image_id'].apply(lambda x: os.path.join(data_dir, 'extra_data', f'{x}')))\n",
    "    y = np.array(df['label'], dtype=int)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def get_unlabeled(dataset_dir, healthy_eye_fraction=1):\n",
    "    df= pd.read_csv(os.path.join(dataset_dir, 'unlabeled.csv'))\n",
    "    x = np.array(df['image_id'].apply(lambda x: os.path.join(data_dir, 'unlabeled', f'{x}')))\n",
    "    y = np.array([UNLABELED_CLASS] * len(x), dtype=int)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def append_train_test(existing, to_add):\n",
    "    train_x, train_y, valid_x, valid_y = existing\n",
    "    tx, vx, ty, vy = to_add\n",
    "    train_x.extend(tx)\n",
    "    train_y.extend(ty)\n",
    "    valid_x.extend(vx)\n",
    "    valid_y.extend(vy)\n",
    "    return train_x, train_y, valid_x, valid_y\n",
    "\n",
    "\n",
    "def get_dataset(datasets: List[str], data_dir='data', random_state=42):\n",
    "    \"\"\"\n",
    "    :param datasets: List \"aptos2015-train/fold0\", \"messidor\",\n",
    "    :param fold:\n",
    "    :param folds:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    all_x = []\n",
    "    all_y = []\n",
    "    sizes = []\n",
    "\n",
    "    for ds in datasets:\n",
    "\n",
    "        dataset_name = ds\n",
    "\n",
    "        if dataset_name == 'current_train':\n",
    "            x, y = get_current_train(data_dir)\n",
    "        elif dataset_name == 'extra_train':\n",
    "            x, y = get_extra_train(data_dir)\n",
    "        elif dataset_name == 'unlabeled':\n",
    "            x, y = get_aptos2015_test(data_dir)\n",
    "        else:\n",
    "            raise ValueError(dataset_name)\n",
    "\n",
    "        all_x.extend(x)\n",
    "        all_y.extend(y)\n",
    "        sizes.append(len(x))\n",
    "\n",
    "    return all_x, all_y, sizes\n",
    "\n",
    "\n",
    "def get_datasets_universal(\n",
    "        train_on: List[str],\n",
    "        valid_on: List[str],\n",
    "        data_dir='data',\n",
    "        image_size=(512, 512),\n",
    "        augmentation='medium',\n",
    "        target_dtype=int,\n",
    "        random_state=42,\n",
    "        coarse_grading=False,\n",
    "        folds=4) -> Tuple[TaskDataset, TaskDataset, List]:\n",
    "    train_x, train_y, sizes = get_dataset(train_on, data_dir=data_dir, random_state=random_state)\n",
    "    valid_x, valid_y, _ = get_dataset(valid_on, data_dir=data_dir, random_state=random_state)\n",
    "\n",
    "    train_transform = get_train_transform(augmentation = augmentation, image_size = image_size)\n",
    "    valid_transform = get_test_transform(image_size = image_size)\n",
    "\n",
    "    train_ds = TaskDataset(train_x, train_y, image_size,\n",
    "                                  transform=train_transform,\n",
    "                                  dtype=target_dtype)\n",
    "\n",
    "    valid_ds = TaskDataset(valid_x, valid_y, image_size,\n",
    "                                  transform=valid_transform,\n",
    "                                  dtype=target_dtype)\n",
    "\n",
    "    return train_ds, valid_ds, sizes\n",
    "\n",
    "\n",
    "def get_datasets(\n",
    "        data_dir='data',\n",
    "        image_size=(512, 512),\n",
    "        augmentation='medium',\n",
    "        use_current=True,\n",
    "        use_extra=False,\n",
    "        use_unlabeled=False,\n",
    "        target_dtype=int,\n",
    "        random_state=42,\n",
    "        fold=None,\n",
    "        folds=4) -> Tuple[TaskDataset, TaskDataset, List]:\n",
    "    assert use_current or use_extra or use_unlabeled\n",
    "\n",
    "    trainset_sizes = []\n",
    "    data_split = [], [], [], []\n",
    "\n",
    "  \n",
    "\n",
    "    if use_current:\n",
    "        x, y = get_current_train(data_dir)\n",
    "        split = split_train_valid(x, y, fold=fold, folds=folds, random_state=random_state)\n",
    "        data_split = append_train_test(data_split, split)\n",
    "        trainset_sizes.append(len(split[0]))\n",
    "\n",
    "    if use_extra:\n",
    "        x, y = get_extra_train(data_dir)\n",
    "        split = split_train_valid(x, y, fold=fold, folds=folds, random_state=random_state)\n",
    "        data_split = append_train_test(data_split, split)\n",
    "        trainset_sizes.append(len(split[0]))\n",
    "\n",
    "    if use_unlabeled:\n",
    "        x, y = get_unlabeled(data_dir)\n",
    "        split = split_train_valid(x, y, fold=fold, folds=folds, random_state=random_state)\n",
    "        data_split = append_train_test(data_split, split)\n",
    "        trainset_sizes.append(len(split[0]))\n",
    "\n",
    "    train_x, train_y, valid_x, valid_y = data_split\n",
    "\n",
    "\n",
    "\n",
    "    train_transform = get_train_transform(augmentation = augmentation, image_size = image_size)\n",
    "    valid_transform = get_test_transform(image_size)\n",
    "\n",
    "    train_ds = TaskDataset(train_x, train_y, image_size, \n",
    "                                      transform=train_transform,\n",
    "                                      dtype=target_dtype)\n",
    "\n",
    "    valid_ds = TaskDataset(valid_x, valid_y, image_size, \n",
    "                                  transform=valid_transform,\n",
    "                                  dtype=target_dtype)\n",
    "\n",
    "    return train_ds, valid_ds, trainset_sizes\n",
    "\n",
    "\n",
    "def get_dataloaders(train_ds, valid_ds,\n",
    "                    batch_size,\n",
    "                    num_workers = 1,\n",
    "                    fast=False,\n",
    "                    train_sizes=None,\n",
    "                    balance=False,\n",
    "                    balance_datasets=False,\n",
    "                    balance_unlabeled=False,\n",
    "                    ):\n",
    "    sampler = None\n",
    "    weights = None\n",
    "    num_samples = 0\n",
    "\n",
    "    if balance_unlabeled:\n",
    "        labeled_mask = (train_ds.targets != UNLABELED_CLASS).astype(np.uint8)\n",
    "        weights = compute_sample_weight('balanced', labeled_mask)\n",
    "        num_samples = int(np.mean(train_sizes))\n",
    "\n",
    "    if balance:\n",
    "        weights = compute_sample_weight('balanced', train_ds.targets)\n",
    "        hist = np.bincount(train_ds.targets)\n",
    "        min_class_counts = int(min(hist))\n",
    "        num_classes = len(np.unique(train_ds.targets))\n",
    "        num_samples = min_class_counts * num_classes\n",
    "\n",
    "    if balance_datasets:\n",
    "        assert train_sizes is not None\n",
    "        dataset_balancing_term = []\n",
    "\n",
    "        for subset_size in train_sizes:\n",
    "            full_dataset_size = float(sum(train_sizes))\n",
    "            dataset_balancing_term.extend([full_dataset_size / subset_size] * subset_size)\n",
    "\n",
    "        dataset_balancing_term = np.array(dataset_balancing_term)\n",
    "        if weights is None:\n",
    "            weights = np.ones(len(train_ds.targets))\n",
    "\n",
    "        weights = weights * dataset_balancing_term\n",
    "        num_samples = int(np.mean(train_sizes))\n",
    "\n",
    "    # If we do balancing, let's go for fixed number of batches (half of dataset)\n",
    "    if weights is not None:\n",
    "        sampler = WeightedRandomSampler(weights, num_samples)\n",
    "\n",
    "    if fast:\n",
    "        weights = np.ones(len(train_ds))\n",
    "        sampler = WeightedRandomSampler(weights, 16)\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size,\n",
    "                          shuffle=sampler is None, sampler=sampler,\n",
    "                          pin_memory=True, drop_last=True)\n",
    "    valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=False,\n",
    "                          pin_memory=True, drop_last=False)\n",
    "\n",
    "    return train_dl, valid_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds, train_sizes = get_datasets(data_dir='../data',\n",
    "                                                    use_current=True,\n",
    "                                                    use_extra=False,\n",
    "                                                    image_size=(28, 28),  \n",
    "                                                    augmentation='medium',\n",
    "                                                    target_dtype=int,\n",
    "                                                    fold=1,\n",
    "                                                    folds=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 28, 28])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds[0]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16048"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader = get_dataloaders(train_ds, valid_ds,\n",
    "                                                batch_size=128,\n",
    "                                                train_sizes=train_sizes,\n",
    "                                                num_workers = 1,\n",
    "                                                balance=True,\n",
    "                                                balance_datasets=True,\n",
    "                                                balance_unlabeled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from catalyst.dl import SupervisedRunner, EarlyStoppingCallback\n",
    "from catalyst.utils import load_checkpoint, unpack_checkpoint\n",
    "\n",
    "loaders = collections.OrderedDict()\n",
    "loaders[\"train\"] = train_loader\n",
    "loaders[\"valid\"] = valid_loader\n",
    "\n",
    "runner = SupervisedRunner(input_key='image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 * Epoch (train): 100% 125/125 [02:17<00:00,  1.10s/it, accuracy01=0.289, accuracy03=0.703, loss=105.665]\n",
      "Early exiting                                                                                             \n",
      "1/10 * Epoch (valid):  50% 21/42 [00:18<00:18,  1.15it/s, accuracy01=0.586, accuracy03=0.852, loss=75.257]"
     ]
    }
   ],
   "source": [
    "import catalyst \n",
    "from catalyst.dl import AccuracyCallback\n",
    "\n",
    "# criterions = LabelSmoothingLoss()\n",
    "criterions = TemperedLogLoss()\n",
    "# optimizer = catalyst.contrib.nn.optimizers.radam.RAdam(model.parameters(), lr = learning_rate)\n",
    "optimizer = catalyst.contrib.nn.optimizers.Adam(model.parameters(), lr = 1e-3)\n",
    "# criterions = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# cappa = CappaScoreCallback()\n",
    "callbacks = [AccuracyCallback(num_classes=5)]\n",
    "\n",
    "main_metric = 'accuracy01'\n",
    "\n",
    "runner.train(\n",
    "    fp16=True,\n",
    "    model=model,\n",
    "    criterion=criterions,\n",
    "    optimizer=optimizer,\n",
    "    callbacks=callbacks,\n",
    "    loaders=loaders,\n",
    "    num_epochs=10,\n",
    "    verbose=1,\n",
    "    main_metric=main_metric,\n",
    "    minimize_metric=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(valid_loader))['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model(next(iter(valid_loader))['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Количество параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEResNext50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26562549"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "seresnext50_model = SEResNext50(512, 5)\n",
    "sum(p.numel() for p in seresnext50_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EfficientNetB6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44223429"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efnB6_model = EfnB6(512, 5)\n",
    "sum(p.numel() for p in efnB6_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
